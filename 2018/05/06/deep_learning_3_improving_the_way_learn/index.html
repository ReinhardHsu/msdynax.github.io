






    
      
    

<!doctype html>
<html lang="">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="author" content="Reinhard Hsu">
  
  
  
  
    <meta name="description" content="反向传播算法是大多数神经网络的基础，我们应该多花点时间掌握它。
还有一些技术能够帮助我们改进反向传播算法，从而改进神经网络的学习方式，包括：

选取更好的代价函数
正则化方法
初始化权重的方法
如何选择网络的超参

Cost Function这里来看一个非常简单的神经元，我们输入1，期望它输出0。

我们看看 Gradient Descent 是如何帮助我们学习 Weights 和 Bias...">
  
  <title>Deep Learning - 3 改进神经网络的学习方式 - Reinhard Hsu</title>
  
  
    <link rel="shortcut icon" href="../../../../favicon.ico">
  
  
  <link rel="stylesheet" href="../../../../css/random.css">
<link rel="stylesheet" href="../../../../css/vegas.min.css">
<link rel="stylesheet" href="../../../../css/highlight-railscasts.css">
<link rel="stylesheet" href="../../../../css/jquery.fancybox.css">
<link rel="stylesheet" href="../../../../css/iconfont/iconfont.css">
<link rel="stylesheet" href="../../../../css/jquery.fancybox-thumbs.css">
<link rel="stylesheet" href="../../../../css/plyr.css">
  
</head>

<body>
<div class="side-navigate hide-area">
  
    <div class="item prev">
      <a href="../../12/test/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        test
      </div>
    </div>
  
  
    <div class="item next">
      <a href="../../03/deep_learning_2_backpropagation/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        Deep Learning - 2 反向传播
      </div>
    </div>
  
</div>
<div id="outer-container" class="hide-area">
<div id="container">
  <div id="menu-outer" class="slide-down">
    <div id="menu-inner">
      <div id="brand">
        
        <a onClick="openUserCard()">
          <img id="avatar" src="http://ReinhardHsu.com/images/ReinhardHsu.png"/>
          <div id="homelink">Reinhard Hsu</div>
        </a>
      </div>
      <div id="menu-list">
        <ul>
        
        
          
            <li>
          
            
              <li><a href="/">Home</a></li>
            
            
          </li>
        
          
            <li>
          
            
              <a href="http://www.cnblogs.com/msdynax">Blog</a>
            
            
          </li>
        
          
            <li>
          
            
              <a href="../../../../archives">Archives</a>
            
            
          </li>
        
          
            <li>
          
            
              <a href="../../../../tags">Tags</a>
            
            
          </li>
        
          
            <li>
          
            
              <a href="../../../../categories">Categories</a>
            
            
          </li>
        
          
            <li>
          
            
              <a href="../../../../about">About</a>
            
            
          </li>
        
          
            <li>
          
            
              <a href="../../../../game.html">Game</a>
            
            
          </li>
        
        </ul>
      </div>
      <div id="show-menu">
        <button>Menu</button>
      </div>
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      
      
  <article id="post">
    <h1>Deep Learning - 3 改进神经网络的学习方式</h1>
    <p class="page-title-sub">
      <span id = "post-title-date">Created at 2018-05-06</span>
      
        <span id = "post-title-updated">Updated at 2018-05-06</span>
      
      
      <span id = "post-title-categories">Category
      
      
        
        
        <a href="../../../../categories/deep-learning/">Deep Learning</a>
      
      </span>
      
      
      <span id = "post-title-tags">
      Tag
      
      
        
        
        <a href="../../../../tags/data-analysis/">Data Analysis</a>
      
        
          /
        
        
        <a href="../../../../tags/machine-learning/">Machine Learning</a>
      
        
          /
        
        
        <a href="../../../../tags/deep-learning/">Deep Learning</a>
      
        
          /
        
        
        <a href="../../../../tags/neural-networks/">Neural Networks</a>
      
        
          /
        
        
        <a href="../../../../tags/backpropagation/">Backpropagation</a>
      
      </span>
      
    </p>
    
    <p>反向传播算法是大多数神经网络的基础，我们应该多花点时间掌握它。</p>
<p>还有一些技术能够帮助我们改进反向传播算法，从而改进神经网络的学习方式，包括：</p>
<ul>
<li>选取更好的代价函数</li>
<li>正则化方法</li>
<li>初始化权重的方法</li>
<li>如何选择网络的超参</li>
</ul>
<h2 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h2><p>这里来看一个非常简单的神经元，我们输入1，期望它输出0。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fr1gu9e1glj308v03bjr7.jpg" alt=""></p>
<p>我们看看 Gradient Descent 是如何帮助我们学习 Weights 和 Biases 的。</p>
<h3 id="Round-1"><a href="#Round-1" class="headerlink" title="Round 1"></a>Round 1</h3><p>我们的初始值如下：<br>$$<br>Weight = 0.6 \<br>Bias = 0.9 \<br>\eta = 0.15<br>$$<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fr1gtjoj3hj30e3084q32.jpg" alt=""></p>
<p>这个神经元的初始输出是 0.82 。</p>
<p>我们看到神经元能够迅速地学习 Weights 和 Biases ，经过300 epoch 的学习，最终输出是 0.09，已经很接近我们的预期 0 ，这个结果已经足够好了。</p>
<h3 id="Round-2"><a href="#Round-2" class="headerlink" title="Round 2"></a>Round 2</h3><p>我们修改下初始值，再来看下：<br>$$<br>Weight = 2 \<br>Bias = 2 \<br>\eta = 0.15<br>$$<br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1h35f8i6j30e4080aa7.jpg" alt=""></p>
<p>这个神经元的初始输出是 0.98 。</p>
<p>尽管 Learning Rate 一样，但是我们看到学习在一开始非常缓慢。看起来在前150 epoch ，Weights 和 Biases 都没有改变太多。</p>
<p>从这个例子我们可以看出，人工神经元在误差很大的时候，学习遇到了问题，学习速度变慢了。</p>
<h3 id="为什么学习速度变慢"><a href="#为什么学习速度变慢" class="headerlink" title="为什么学习速度变慢"></a>为什么学习速度变慢</h3><p>神经元的学习方式：</p>
<p>通过计算代价函数的偏导 $\frac{\partial C}{\partial w}$ 和 $\frac{\partial C}{\partial b}$ 来改变 Weights 和 Biases 。</p>
<p>我们说学习速度变慢，实际上是在说偏导很小。</p>
<h3 id="为什么偏导很小"><a href="#为什么偏导很小" class="headerlink" title="为什么偏导很小"></a>为什么偏导很小</h3><p>我们的代价函数是均方误差代价函数<br>$$<br>C = \frac{ (y-a)^2 }{2}<br>$$</p>
<ul>
<li>a是x=1时神经元的输出</li>
<li>y=0是期待的输出</li>
</ul>
<p>在激活函数是Sigmoid函数时<br>$$<br>a = \sigma(z) \<br>z = wx+b<br>$$<br>代价函数的偏导是<br>$$<br>\frac{\partial C}{\partial w} = (a-y) \sigma’(z) x \<br>\frac{\partial C}{\partial b} = (a-y) \sigma’(z) \<br>$$<br>当x=1，y=0时<br>$$<br>\frac{\partial C}{\partial w} = a \sigma’(z) \<br>\frac{\partial C}{\partial b} = a \sigma’(z) \<br>$$<br>我们来看下Sigmoid函数的形状</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fr1iygklo3j30bj07tdfw.jpg" alt=""></p>
<p>当神经元的输出接近1时，曲线变得非常平缓，$\sigma’(z)$ 就变得非常小，从而 代价函数的偏导 $\frac{\partial C}{\partial w}$ 和 $\frac{\partial C}{\partial b}$ 也会变得非常小。</p>
<p>这就是学习速度变慢的根源。</p>
<h3 id="Cross-Entropy-Cost-Function"><a href="#Cross-Entropy-Cost-Function" class="headerlink" title="Cross Entropy Cost Function"></a>Cross Entropy Cost Function</h3><p>那么，我们换个代价函数能不能解决上面的问题？</p>
<p>再看拥有多个输入变量神经元模型</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fr1jc75wypj308j0480sl.jpg" alt=""><br>$$<br>z = \sum_j w_j x_j + b<br>$$</p>
<ul>
<li>这里 z 是输入的加权求和。</li>
</ul>
<p>我们为这个神经元定义交叉熵代价函数如下：<br>$$<br>  C = -\frac{1}{n} \sum_x \left[y \ln a + (1-y ) \ln (1-a) \right]<br>$$</p>
<ul>
<li>n是训练数据的个数</li>
<li>求和是针对所有训练输入样本x</li>
<li>y是我们对每个样本x所期望的相应地输出</li>
</ul>
<h4 id="均方误差代价函数和交叉熵代价函数都有两个特点"><a href="#均方误差代价函数和交叉熵代价函数都有两个特点" class="headerlink" title="均方误差代价函数和交叉熵代价函数都有两个特点"></a>均方误差代价函数和交叉熵代价函数都有两个特点</h4><h5 id="交叉熵是正数"><a href="#交叉熵是正数" class="headerlink" title="交叉熵是正数"></a>交叉熵是正数</h5><ol>
<li>由Sigmoid激活函数的特性可以知道，激活值a的取值介于0和1之间，它们的对数是负数</li>
<li>求和后的数是负数</li>
<li>整个等式前面有一个符号，最终$C&gt;0$</li>
</ol>
<h5 id="当所有输入x的输出都能接近期望输出y时，代价函数接近0"><a href="#当所有输入x的输出都能接近期望输出y时，代价函数接近0" class="headerlink" title="当所有输入x的输出都能接近期望输出y时，代价函数接近0"></a>当所有输入x的输出都能接近期望输出y时，代价函数接近0</h5><p>比如对于样本x，它的<br>$$<br>y = 0 \<br>a \approx 0<br>$$<br>这样，等式的第一项就是0</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fr1kv1gy4ej30ba0cmtaa.jpg" alt=""></p>
<p>从图上可以看出，等式的第二项$\ln(1-a) \approx 0$</p>
<p>对于样本x<br>$$<br>y = 1 \<br>a \approx 1<br>$$<br>等式的第二项为0</p>
<p>等式的第一项$\ln a \approx 0$</p>
<p>上面两种情况，交叉熵代价函数都约等于0</p>
<h4 id="交叉熵独有的特点"><a href="#交叉熵独有的特点" class="headerlink" title="交叉熵独有的特点"></a>交叉熵独有的特点</h4><p>先看下交叉熵关于权重的偏导<br>$$<br>\begin{eqnarray}<br>  \frac{\partial C}{\partial w_j} &amp; = &amp; -\frac{1}{n} \sum_x \left(<br>    \frac{y }{\sigma(z)} -\frac{(1-y)}{1-\sigma(z)} \right)<br>  \frac{\partial \sigma}{\partial w_j} \tag{58}\<br> &amp; = &amp; -\frac{1}{n} \sum_x \left(<br>    \frac{y}{\sigma(z)}<br>    -\frac{(1-y)}{1-\sigma(z)} \right)\sigma’(z) x_j.<br>\tag{59}\end{eqnarray}<br>$$<br>通分简化后<br>$$<br>\begin{eqnarray}<br>  \frac{\partial C}{\partial w_j} &amp; = &amp; \frac{1}{n}<br>  \sum_x \frac{\sigma’(z) x_j}{\sigma(z) (1-\sigma(z))}<br>  (\sigma(z)-y).<br>\tag{60}\end{eqnarray}<br>$$<br>我们知道$\sigma’$<br>$$<br>\sigma(z) = \frac{1}{1+e^{-z}} \<br>\sigma’(z) = \sigma(z)(1-\sigma(z))<br>$$<br>代入到上面的公式中<br>$$<br>\frac{\partial C}{\partial w_j} = \frac{1}{n} \sum_x x_j(\sigma(z)-y)<br>$$<br>从交叉熵关于权重的偏导中，我们看到权重的学习速率可以是被输出结果的误差所控制。</p>
<p>之前均方误差关于权重的偏导中，误差太大导致$\sigma’(z)$非常小，造成学习速度非常慢。</p>
<p>现在交叉熵关于权重的偏导中，$\sigma’(z)$被抵消掉了，因此不会担心误差太大会导致学习速度慢。相反，误差越大我们的神经元学习速率越大。</p>
<h3 id="Round-3"><a href="#Round-3" class="headerlink" title="Round 3"></a>Round 3</h3><p>再来看看使用交叉熵代价函数时的学习速度。<br>$$<br>Weight = 0.6 \<br>Bias = 0.9 \<br>\eta = 0.15<br>$$<br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1mj5ladyj30e7081aa5.jpg" alt=""></p>
<p>对于交叉熵代价函数而言，Learning Rate = 0.15 太高了，学得太快，以至于我们看不清楚代价函数的值是如何变化的。</p>
<p>这里将 Learning Rate 换成 0.005 再看一次。<br>$$<br>Weight = 0.6 \<br>Bias = 0.9 \<br>\eta = 0.005<br>$$<br><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fr1mmeoonvj30e407v74e.jpg" alt=""></p>
<p>我们看到和之前一样好。</p>
<h3 id="Round-4"><a href="#Round-4" class="headerlink" title="Round 4"></a>Round 4</h3><p>$$<br>Weight = 2 \<br>Bias = 2 \<br>\eta = 0.005<br>$$</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1mnswupfj30e907ut8u.jpg" alt=""></p>
<p>我们看到误差太大没有导致学习速度变慢。</p>
<h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><p>激活函数除了Sigmoid，还有Softmax。</p>
<p>第j个输出神经元的激活值 $a_j^L$ 是<br>$$<br>a_j^L = \frac{e^{z_j^L}}{\sum_k e^{z_k^L}}<br>$$<br>分母是对所有输出神经元求和。</p>
<p>从公式我们可以看出，Softmax层的所有输出激活值都是正数，并且它们加起来和为1。</p>
<p>这样就可以把Softmax层得到的输出看作是一个概率分布，将数据激活值 $a_j^L$看作是神经网络认为结果是 j 的概率。</p>
<h3 id="Softmax的单调性"><a href="#Softmax的单调性" class="headerlink" title="Softmax的单调性"></a>Softmax的单调性</h3><p>函数的单调性，指函数的自变量增大或减小，函数值也增大或减小。</p>
<p>Softmax也有这样的特性，当加权输入 $z_j^L$ 增加时，激活值 $a_j^L$ 也增加。</p>
<h3 id="Softmax的非局部性"><a href="#Softmax的非局部性" class="headerlink" title="Softmax的非局部性"></a>Softmax的非局部性</h3><p>sigmoid层的第j个神经元的输出是<br>$$<br>a_j^L = \sigma(z_j^L)<br>$$<br>它是只关于第j个神级元的加权输入的一个函数。</p>
<p>而 Softmax 层的任何一个 $a_j^L$ ，都要依赖该层所有神经元的加权输入。</p>
<h3 id="反转Softmax层"><a href="#反转Softmax层" class="headerlink" title="反转Softmax层"></a>反转Softmax层</h3><p>我们有一个带有Softmax层的神经网络，已知激活值，那么加权输入为：<br>$$<br>z_j^L = \ln a_j^L + C<br>$$</p>
<h3 id="Log-Likelihood-Cost-Function"><a href="#Log-Likelihood-Cost-Function" class="headerlink" title="Log-Likelihood Cost Function"></a>Log-Likelihood Cost Function</h3><p>Sigmoid 输出层与 Cross-Entropy 代价函数搭配</p>
<p>Softmax 输出层与 Log-Likelihood 代价函数搭配</p>
<p>Log-Likelihood 代价函数的公式是：<br>$$<br>C \equiv - \ln a_y^L<br>$$</p>
<ul>
<li>x表示输入网络的训练样本</li>
<li>y是期待的输出，用One-Hot向量表示。y=7表示向量的第7位是1，其余位是0</li>
</ul>
<p>如果输入的是数字 7 对应的图像，那么 Log-Likelihood 代价是<br>$$<br>-\ln a_7^L<br>$$<br>如果网络工作很好，对输出 7 非常自信，$a_7^L$ 会非常接近1，那么$-\ln a_7^L$ 就会很小。</p>
<p>如果网络工作不好，概率 $a_7^L$ 会很小，而 $-\ln a_7^L$ 会很大。</p>
<h3 id="学习速度不会衰退"><a href="#学习速度不会衰退" class="headerlink" title="学习速度不会衰退"></a>学习速度不会衰退</h3><p>$$<br>\begin{eqnarray}<br>  \frac{\partial C}{\partial b^L_j} &amp; = &amp; a^L_j-y_j  \tag{81}\<br>  \frac{\partial C}{\partial w^L_{jk}} &amp; = &amp; a^{L-1}_k (a^L_j-y_j)<br>\tag{82}\end{eqnarray}<br>$$</p>
<p>这些表达式确保我们不会遇到学习速度衰退的问题。</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>$\delta_j^L = a_j^L - y_j$</p>
<h2 id="过拟合和正则化"><a href="#过拟合和正则化" class="headerlink" title="过拟合和正则化"></a>过拟合和正则化</h2><p>Johnny von Neumann 说四个参数可以模拟一头大象，五个参数可以让它摇动鼻子。</p>
<p>Enrico Fermi 认为，拥有大量自由参数的模型能够描述一个足够宽泛的现象。即使这样的模型与现有数据拟合得非常好，但它并没有真正地洞察到现象背后的本质，以至于不能普及到新的情况上。</p>
<p>训练数据的代价</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1pplyz13j30cv0a5dgh.jpg" alt=""></p>
<p>测试数据的准确度</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1pq7tjvvj30cz0acab8.jpg" alt=""></p>
<p>测试数据的代价</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1pqnuvj9j30cm0ajgmi.jpg" alt=""></p>
<p>训练数据的准确度</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fr1pu2k3h3j30ch0a9gma.jpg" alt=""></p>
<p>我们看到，训练数据的代价一直在下降，这可能让我们觉得模型似乎一直在改进。</p>
<p>但是从测试数据的准确度来看，280 epoch 后就几乎停止改善。</p>
<p>从测试数据的代价来看，更直观，在15 epoch前代价一直在降低，但之后却开始变大。而训练数据的代价是一直在降低的。</p>
<p>从训练数据的准确度来看，训练数据的准确率上升到100%，能正确分类所有的训练数据，但是在测试数据上的准确率却直邮82.27% 。</p>
<p>以上种种迹象表明，280 epoch 开始的网络产生了 OverFitting 。</p>
<p>在含有大量 Weights 和 Biases 参数时，神经网络很容易过拟合。我们需要跟踪网络训练过程中测试数据的准确度，如果测数据集的准确度不在提高，就应该停止训练。</p>
<h3 id="Validation-Data"><a href="#Validation-Data" class="headerlink" title="Validation Data"></a>Validation Data</h3><p>我们引入 Validation Data，每一步训练后，计算 Validation Data 的分类准确度，一旦分类准确度达到饱和，就停止训练。这种策略叫做 Early Stopping（提前终止）。</p>
<h4 id="为什么使用-Validation-Data-而不是使用-Test-Data-来苹果结果去设置超参"><a href="#为什么使用-Validation-Data-而不是使用-Test-Data-来苹果结果去设置超参" class="headerlink" title="为什么使用 Validation Data 而不是使用 Test Data 来苹果结果去设置超参"></a>为什么使用 Validation Data 而不是使用 Test Data 来苹果结果去设置超参</h4><p>如果基于 Test Data 去做，有可能我们最后的网络是对 Test Data 过拟合的，网络的性能不能推广到其它数据集。</p>
<p>可以将 Validation Data 看作帮助我们学习合适超参的一种训练数据。</p>
<p>这里超参是指网络层数，隐藏层神经元个数，学习率，批次大小。</p>
<h3 id="增加数据训练数据"><a href="#增加数据训练数据" class="headerlink" title="增加数据训练数据"></a>增加数据训练数据</h3><p>增加训练数据是降低过拟合的最好方法之一。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1qdg6xk7j30cm0abq3p.jpg" alt=""></p>
<p>一样的超参，只是训练图片从1000增加到50000，测试数据和训练数据的准确度更加接近，差距从之前17.73%降低到1.53% 。</p>
<p>虽然过拟合依然存在，但已经大大降低，我们的网络能从训练数据更好地泛化到测试数据。</p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p>除了增加训练数据，还能通过减小网络规模去避免过拟合。但是我们觉得大型网络更有潜力，不愿意减小规模。</p>
<p>在固定网络规模和固定训练数据大小的时候，我们还可以选择 Regularization（正则化）技术。</p>
<p>Weight Decay</p>
<p>权重衰减是最常用的正则化技术，也叫 L2 Regularization（L2 正则）。它的思想是在代价函数中加入一个额外的正则化项。<br>$$<br>C = C_0 + \frac{\lambda}{2n} \sum_w w^2<br>$$</p>
<ul>
<li>$C_0$ 是原本没有正则化的代价函数</li>
<li>第二项是网络中所有 Weights 的平方和</li>
<li>$\lambda$ 是 <em>regularization parameter</em>（正则化参数），并且 $\lambda &gt; 0$</li>
</ul>
<p>当 $\lambda$ 较小时，我们偏好最小化原来的代价函数，当 $\lambda$ 较大时，我们让网络偏好学习更小的 Weights 。</p>
<h4 id="在随机梯度下降算法中应用正则化"><a href="#在随机梯度下降算法中应用正则化" class="headerlink" title="在随机梯度下降算法中应用正则化"></a>在随机梯度下降算法中应用正则化</h4><p>在正则化的网络中应用随机梯度下降算法，对上面的公式求偏导可知：<br>$$<br>\frac{\partial C}{\partial w} = \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} w \<br>\frac{\partial C}{\partial b} = \frac{\partial C_0}{\partial b}<br>$$<br>只要照常使用反向传播，并把 $\frac{\lambda}{n} w$ 代入<br>$$<br>b \rightarrow b - \eta \frac{\partial C_0}{\partial b} \<br>w \rightarrow w - \eta \frac{\partial C_0}{\partial w} - \frac{\eta \lambda}{n} w \<br>= \left(1 - \frac{\eta \lambda}{n}\right) w - \eta \frac{\partial C_0}{\partial w}<br>$$<br>我们看到，跟之前唯一的变化时，我们用 $\left(1 - \frac{\eta \lambda}{n}\right) $ 来调整 Weights ，这种调叫做 Weight Decay（权重衰减）。</p>
<p>之前我们的随机梯度下降，时在包含m个训练样本的mini-batch数据中进行平均以估计$\frac{\partial C_0}{\partial w}$，现在对于随机梯度下降法而言正则化的学习方法变成了：<br>$$<br>w \rightarrow \left(1 - \frac{\eta \lambda}{n}\right) w - \frac{\eta}{m} \sum_x \frac{\partial C_x}{\partial w} \<br>b \rightarrow b - \frac{\eta}{m} \sum_x \frac{\partial C_x}{\partial wb}<br>$$<br>$\sum$ 是针对mini-batch中所有训练样本进行求和</p>
<p>$C_x$ 是每个样本未进行正则化的代价</p>
<p>我们看到，正则化只是增加了权重衰减。</p>
<h4 id="Round-1-1"><a href="#Round-1-1" class="headerlink" title="Round 1"></a>Round 1</h4><p>我们使用 $n = 1000$ 个训练样本再跑一次，这次由30个隐藏层神经元，每个mini-batch的大小是10，学习率是0.5，使用交叉熵代价函数，正则化参数 $\lambda = 0.1$。使用1000个训练样本。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fr1rnh7l1tj30d70agjs3.jpg" alt=""></p>
<p>我们看到训练数据的代价函数一直在下降，与之前没有进行正则化时一样。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fr1rqik8uej30cw0amdh2.jpg" alt=""></p>
<p>但是从测试数据的准确度，我们看到应用正则化抑制了过拟合。</p>
<p>准确度也从之前的82.27上升到87.1 。</p>
<h4 id="Round-2-1"><a href="#Round-2-1" class="headerlink" title="Round 2"></a>Round 2</h4><p>这次将训练样本增加到 $n=50000$ ，相应的，也需要调整正则化参数 $\lambda = 5$，让权重衰减跟之前保持一样。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fr1rxfhc2gj30cm0aqaax.jpg" alt=""></p>
<p>我们之前看到过，对于50000样本量的训练数据，过拟合已经不再是个大问题了。但是应用正则化后，我们在测试数据上的准确度从95.49%提升到96.49% 。</p>
<p>从经验来看，正则化让我们的网络声称得更好，并有效地减弱了过拟合效应。</p>
<h4 id="正则化的好处"><a href="#正则化的好处" class="headerlink" title="正则化的好处"></a>正则化的好处</h4><ul>
<li>减弱过拟合，</li>
<li>提升分类准确率，</li>
<li>避免陷入代价函数的局部最优中</li>
</ul>
<p>使用随机 Weights 初始化时，经常卡在代价函数的局部最优中，结果就是每次运行可能产生相当不同的结果。</p>
<p>而应用了正则化后，每次运行可以提供更容易复现的结果。</p>
<h4 id="为什么正则化能够降低过拟合"><a href="#为什么正则化能够降低过拟合" class="headerlink" title="为什么正则化能够降低过拟合"></a>为什么正则化能够降低过拟合</h4><p>一般的说法是：某种程度上，越小的权重复杂度越低，能更简单有效地描绘数据，所以我们倾向于选择这样的权重。</p>
<div><h1>推荐文章<span style="font-size:0.45em; color:gray">（由<a href="https://github.com/huiwang/hexo-recommended-posts">hexo文章推荐插件</a>驱动）</span></h1><ul><li><a href="http://reinhardhsu.com/2017/07/17/career_richdad_team_ppdai_magic_mirror_cup_second_fintech_data_application_competition/">Career 祝贺富爸爸队的投资分析作品成功进入拍拍贷魔镜杯复赛阶段</a></li><li><a href="http://reinhardhsu.com/2016/09/25/data_analysis_commucating_data_art/">Data Analysis 数据交流的艺术</a></li><li><a href="http://reinhardhsu.com/2016/09/19/data_analysis_different_roles_of_bi_field/">Data Analysis 商业智能领域里的不同角色</a></li></ul></div>
  </article>
  <div class="random-toc-area">
  <button class="btn-hide-toc btn-hide-toc-show" style="display: none" onclick="TOCToggle()">Show TOC</button>
  <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">Hide TOC</button>
  <div class="random-toc">
    <h2>Table of Content</h2>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Cost-Function"><span class="toc-text">Cost Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Round-1"><span class="toc-text">Round 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Round-2"><span class="toc-text">Round 2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么学习速度变慢"><span class="toc-text">为什么学习速度变慢</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么偏导很小"><span class="toc-text">为什么偏导很小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cross-Entropy-Cost-Function"><span class="toc-text">Cross Entropy Cost Function</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#均方误差代价函数和交叉熵代价函数都有两个特点"><span class="toc-text">均方误差代价函数和交叉熵代价函数都有两个特点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#交叉熵是正数"><span class="toc-text">交叉熵是正数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#当所有输入x的输出都能接近期望输出y时，代价函数接近0"><span class="toc-text">当所有输入x的输出都能接近期望输出y时，代价函数接近0</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#交叉熵独有的特点"><span class="toc-text">交叉熵独有的特点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Round-3"><span class="toc-text">Round 3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Round-4"><span class="toc-text">Round 4</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Softmax"><span class="toc-text">Softmax</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Softmax的单调性"><span class="toc-text">Softmax的单调性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Softmax的非局部性"><span class="toc-text">Softmax的非局部性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反转Softmax层"><span class="toc-text">反转Softmax层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Log-Likelihood-Cost-Function"><span class="toc-text">Log-Likelihood Cost Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习速度不会衰退"><span class="toc-text">学习速度不会衰退</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反向传播"><span class="toc-text">反向传播</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过拟合和正则化"><span class="toc-text">过拟合和正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Validation-Data"><span class="toc-text">Validation Data</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#为什么使用-Validation-Data-而不是使用-Test-Data-来苹果结果去设置超参"><span class="toc-text">为什么使用 Validation Data 而不是使用 Test Data 来苹果结果去设置超参</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#增加数据训练数据"><span class="toc-text">增加数据训练数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Regularization"><span class="toc-text">Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#在随机梯度下降算法中应用正则化"><span class="toc-text">在随机梯度下降算法中应用正则化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Round-1-1"><span class="toc-text">Round 1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Round-2-1"><span class="toc-text">Round 2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#正则化的好处"><span class="toc-text">正则化的好处</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#为什么正则化能够降低过拟合"><span class="toc-text">为什么正则化能够降低过拟合</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-text">推荐文章（由hexo文章推荐插件驱动）</span></a>
  </div>
</div>

  
<nav id="pagination">
  
    <a href="../../12/test/" class="prev">&larr; Prev post test</a>
  

  

  
    <a href="../../03/deep_learning_2_backpropagation/" class="next">Next post Deep Learning - 2 反向传播 &rarr;</a>
  
</nav>

  <!-- JiaThis Button BEGIN -->

<!-- JiaThis Button END -->


      
      <div id="uyan_frame"></div>
      
      
      
    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      Site by Reinhard Hsu using
      <a href="http://hexo.io">Hexo</a> & <a href="https://github.com/stiekel/hexo-theme-random">Random</a>
      <br>
      
    </div>
  </div>
</div>

</div>


  <!-- VL BEGIN -->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script type="text/javascript">
new Valine({
    el: '#uyan_frame' ,
    notify:false, 
    verify:false, 
    appId: 'TWoEQAlGPJwcRhNfqjKsmBUI-gzGzoHsz',
    appKey: 'cuCvIecOqw2bk7bDoReqTDWj',
    placeholder: 'just go go',
    path:window.location.pathname, 
    avatar:'mm' 
});
</script>
<!-- VL END -->


<div id="user-card">
  <div class="center-field">
    <img class="avatar" src="http://ReinhardHsu.com/images/ReinhardHsu.png">
    <p id="description"></p>
    <ul class="social-icon">
  
  
    <li>
      <a href="https://github.com/ReinhardHsu">
        
          <i class="icon iconfont github">&#xe606;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://twitter.com/ReinhardHsu">
        
          <i class="icon iconfont twitter">&#xe600;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.facebook.com/reinhardhsu">
        
          <i class="icon iconfont facebook">&#xe604;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.douban.com/people/Reinhaid">
        
          <i class="icon iconfont douban">&#xe60f;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.zhihu.com/people/reinhardhsu">
        
          <i class="icon iconfont zhihu">&#xe60b;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.linkedin.com/in/ReinhardHsu">
        
          <i class="icon iconfont linkedin">&#xe601;</i>
        
      </a>
    </li>
  
</ul>
  </div>
</div>


<div id="btn-view">Hide</div>

<script>
// is trigger analytics / tongji script
var isIgnoreHost = false;

if(window && window.location && window.location.host) {
  isIgnoreHost = ["localhost","127.0.0.1"].some(function(address){
    return 0 === window.location.host.indexOf(address);
  });
}

var isTriggerAnalytics = !( true && isIgnoreHost );

</script>

  <script>
if(isTriggerAnalytics) {
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?9ddaf4c58daefd4b2d98d95e643549b3";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
}
</script>



  <script>
if(isTriggerAnalytics) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-119133633-1', 'auto');
  ga('send', 'pageview');
}

</script>



  
  
    <script src="../../../../js/jquery-2.2.3.min.js"></script>
  
    <script src="../../../../js/vegas.min.js"></script>
  
    <script src="../../../../js/random.js"></script>
  
    <script src="../../../../js/highlight.pack.js"></script>
  
    <script src="../../../../js/jquery.mousewheel.pack.js"></script>
  
    <script src="../../../../js/jquery.fancybox.pack.js"></script>
  
    <script src="../../../../js/jquery.fancybox-thumbs.js"></script>
  
    <script src="../../../../js/plyr.js"></script>
  

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script>

  // fancybox
  var backgroundImages = [];
  
  $('#post').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox') || $(this).parent().hasClass('fancybox-thumb')) return;
      var alt = this.alt || this.title;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'post' + i);
    });
  });
  $(".fancybox").fancybox();

var vegasConfig = {"preload­Image":true,"transition":["slideLeft2","slideRight2","flash2"],"timer":true,"delay":5000,"shuffle":true,"count":28};
var unsplashConfig = {"gravity":"north"};
// is show background images
var turnoffBackgroundImage = false;




var backgroundColor = "D7CCC8";

$(".fancybox-thumb").fancybox({
  prevEffect: 'none',
  nextEffect: 'none',
  helpers: {
    title: {
      type: 'outside'
    },
    thumbs: {
      width: 50,
      height: 50
    }
  }
});

// show video with plyr
$(".video-container iframe").each(function(i){
  var url = $(this).attr('src');
  var id = url.split('/').pop();
  var plyrContainer = document.createElement('div');
  plyrContainer.className = 'plyr';
  var plyrElement = document.createElement('div');
  plyrElement.dataset.videoId = id;
  switch(true) {
    case url.search('youtube.com') >= 0:
      plyrElement.dataset.type = 'youtube';
      break;
    case url.search('vimeo.com') >= 0:
      plyrElement.dataset.type = 'vimeo';
      break;
    default:
      return;
  };
  plyrContainer.appendChild(plyrElement);
  $(this).parent().html(plyrContainer);
});
plyr.setup('.plyr', {iconUrl: '../../../../css/sprite.svg'});
</script>
</body>
</html>

